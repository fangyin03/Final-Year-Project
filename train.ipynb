{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5afe83c-90e0-42a3-a492-110f3e42b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "from fused_encoder import create_fused_encoder\n",
    "from triplet_generator import prepare_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce95eb-13f2-4ae2-ad34-6b3778cf90be",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_DIR = \"train-Copy1\"\n",
    "TRAIN_AUDIO_DIR = \"audiotrain\"\n",
    "VAL_IMG_DIR = \"val-Copy1\"\n",
    "VAL_AUDIO_DIR = \"audio_val(2)-Copy1\"\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "MARGIN = 0.5\n",
    "OUTPUT_DIR = \"model_outputs_strong\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "905b3416-9cf7-440b-9b92-b0bf1a897fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred):\n",
    "    anchor, positive, negative = tf.split(y_pred, num_or_size_splits=3, axis=1)\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "    loss = tf.maximum(pos_dist - neg_dist + MARGIN, 0.0)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def create_triplet_model(encoder):\n",
    "    a_img = tf.keras.Input(shape=(224, 224, 3))\n",
    "    a_audio = tf.keras.Input(shape=(None, 1024))\n",
    "    p_img = tf.keras.Input(shape=(224, 224, 3))\n",
    "    p_audio = tf.keras.Input(shape=(None, 1024))\n",
    "    n_img = tf.keras.Input(shape=(224, 224, 3))\n",
    "    n_audio = tf.keras.Input(shape=(None, 1024))\n",
    "\n",
    "    a_emb = encoder([a_img, a_audio])\n",
    "    p_emb = encoder([p_img, p_audio])\n",
    "    n_emb = encoder([n_img, n_audio])\n",
    "\n",
    "    out = tf.keras.layers.Concatenate(axis=1)([a_emb, p_emb, n_emb])\n",
    "    return tf.keras.Model(inputs=[a_img, a_audio, p_img, p_audio, n_img, n_audio], outputs=out)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.environ['TFHUB_CACHE_DIR'] = os.path.join(os.getcwd(), 'tfhub_cache')\n",
    "if not os.path.exists(os.environ['TFHUB_CACHE_DIR']):\n",
    "    os.makedirs(os.environ['TFHUB_CACHE_DIR'])\n",
    "\n",
    "try:\n",
    "    yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YAMNet: {e}\")\n",
    "    # Clear cache and try again\n",
    "    cache_dir = os.environ['TFHUB_CACHE_DIR']\n",
    "    if os.path.exists(cache_dir):\n",
    "        for root, dirs, files in os.walk(cache_dir, topdown=False):\n",
    "            for name in files:\n",
    "                os.remove(os.path.join(root, name))\n",
    "            for name in dirs:\n",
    "                os.rmdir(os.path.join(root, name))\n",
    "        os.rmdir(cache_dir)\n",
    "    yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c8953-0ae9-45ff-aa08-1d32151c6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing training triplets...\")\n",
    "train_triplets = prepare_triplets(TRAIN_IMG_DIR, TRAIN_AUDIO_DIR, yamnet_model)\n",
    "print(\"Preparing validation triplets...\")\n",
    "val_triplets = prepare_triplets(VAL_IMG_DIR, VAL_AUDIO_DIR, yamnet_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d436962a-b64c-43ec-a16c-1089cda445bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(triplets, batch_size):\n",
    "    while True:\n",
    "        np.random.shuffle(triplets)\n",
    "        for i in range(0, len(triplets), batch_size):\n",
    "            batch = triplets[i:i+batch_size]\n",
    "            if not batch: continue\n",
    "            a_img, a_audio, p_img, p_audio, n_img, n_audio = zip(*batch)\n",
    "            #a_img = [tf.image.resize(tf.io.decode_image(tf.io.read_file(x), channels=3)/255., (224,224)) for x in a_img]\n",
    "            #p_img = [tf.image.resize(tf.io.decode_image(tf.io.read_file(x), channels=3)/255., (224,224)) for x in p_img]\n",
    "            #n_img = [tf.image.resize(tf.io.decode_image(tf.io.read_file(x), channels=3)/255., (224,224)) for x in n_img]\n",
    "            a_img = [tf.image.resize(tf.cast(tf.io.decode_image(tf.io.read_file(x), channels=3), tf.float32) / 255.0, (224, 224)) if x != 'empty_image' else tf.zeros((224, 224, 3)) for x in a_img]\n",
    "            p_img = [tf.image.resize(tf.cast(tf.io.decode_image(tf.io.read_file(x), channels=3), tf.float32) / 255.0, (224, 224)) if x != 'empty_image' else tf.zeros((224, 224, 3)) for x in p_img]\n",
    "            n_img = [tf.image.resize(tf.cast(tf.io.decode_image(tf.io.read_file(x), channels=3), tf.float32) / 255.0, (224, 224)) if x != 'empty_image' else tf.zeros((224, 224, 3)) for x in n_img]\n",
    "            yield [tf.stack(a_img), tf.stack(a_audio),\n",
    "                   tf.stack(p_img), tf.stack(p_audio),\n",
    "                   tf.stack(n_img), tf.stack(n_audio)], tf.zeros((len(batch),))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f277e836-0cc2-4450-89d4-07fd43dba08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_fused_encoder()\n",
    "triplet_model = create_triplet_model(encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5ce54-ec54-4b86-95e3-0e3ccd685028",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE), loss=triplet_loss)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(os.path.join(OUTPUT_DIR, \"triplet_model\"), save_best_only=True),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=os.path.join(OUTPUT_DIR, \"logs\"))\n",
    "]\n",
    "\n",
    "steps_per_epoch = len(train_triplets) // BATCH_SIZE\n",
    "val_steps = len(val_triplets) // BATCH_SIZE\n",
    "\n",
    "history = triplet_model.fit(\n",
    "    generator(train_triplets, BATCH_SIZE),\n",
    "    validation_data=generator(val_triplets, BATCH_SIZE),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "encoder.save(os.path.join(OUTPUT_DIR, \"fused_encoder_triplet\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9bcdf-897b-4291-8980-2a53274ab580",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Triplet Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Val\"])\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"triplet_training_history.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3104af-87d0-4379-8bb4-c37d092e4a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu_env)",
   "language": "python",
   "name": "tf_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
